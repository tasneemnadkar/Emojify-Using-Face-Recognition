{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59971ca5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dee5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the training and validation generators\n",
    "\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "train_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264a9ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Building the CNN architecture\n",
    "# with four conv2D layers, two dense layers and one flatten layer\n",
    "\n",
    "recognition_model = Sequential()\n",
    "\n",
    "recognition_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "recognition_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "\n",
    "recognition_model.add(Flatten())\n",
    "recognition_model.add(Dense(1024, activation='relu'))\n",
    "recognition_model.add(Dropout(0.5))\n",
    "recognition_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab66114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Model Summary\n",
    "\n",
    "recognition_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c30e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Disable OpenCL\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be16edc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "\n",
    "recognition_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001, decay=1e-6),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870bdaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "recognition_model_info = recognition_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=60,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained Model Weights\n",
    "\n",
    "recognition_model.save_weights('recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73855370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "plt.plot(recognition_model_info.history['accuracy'])\n",
    "plt.plot(recognition_model_info.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.plot(recognition_model_info.history['loss'])\n",
    "plt.plot(recognition_model_info.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2eff6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Facial emotion Dictonary with values\n",
    "\n",
    "facial_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7ace4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start the webcam feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Find haar cascade to draw bounding box around face\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    bounding_box = cv2.CascadeClassifier('haarcascades_cuda/haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
    "        facial_prediction = recognition_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(facial_prediction))\n",
    "        cv2.putText(frame, facial_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
